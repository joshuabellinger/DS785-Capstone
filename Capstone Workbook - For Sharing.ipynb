{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Reader, Dataset, KNNBasic, NormalPredictor,BaselineOnly,KNNWithMeans,KNNBaseline\n",
    "from surprise import SVD, SVDpp, NMF, SlopeOne, CoClustering\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import accuracy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load datasets\n",
    "purchase = pd.read_excel('UWL_Purchase Data - Expanded2.xlsx')\n",
    "customer = pd.read_excel('UWL_Customer Data - Expanded.xlsx')\n",
    "### store data removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### explore purchase data\n",
    "display(purchase.head())\n",
    "purchase.dtypes\n",
    "np.where(pd.isnull(purchase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change column names for clarity and ease of coding\n",
    "purchase.columns = ['Customer_ID','Date','Day','TimeOfDay','DaySegment','TimeSegment','StoreNo','CatManDepartment','CatManSubCat',\n",
    "                   'PrdCatSubCat','UPCDescription','UPC','QtySold','Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### explore customer data\n",
    "display(customer.head())\n",
    "customer.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### exploration of store data removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_customers = len(pd.unique(purchase['Customer_ID'])) ### identify number of unique customers\n",
    "num_prod_purchases = len(purchase) ### of products purchased\n",
    "num_products = len(pd.unique(purchase['UPCDescription'])) ### unique products in dataset\n",
    "print(\"There are \", num_customers, \"unique customers, among \", num_prod_purchases, \"items purchased.\")\n",
    "print(\"There are \", num_products, \"products represented in the dataset.\")\n",
    "purchase['UniquePurchases'] = str(purchase['Customer_ID']) + purchase['Date'] + purchase['TimeOfDay'] ### create unique transaction ID\n",
    "num_purchases = len(pd.unique(purchase['UniquePurchases'])) ### number of unique transactions\n",
    "print('There are ',num_purchases,'unique purchases.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove fuel from dataset\n",
    "purchase.drop(purchase.index[purchase[\"CatManDepartment\"] == \"Fuel\"],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### replace brand name prefixes\n",
    "### code removed for anonymization purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### change quantity sold of all items to 1, just want to know if they bought the item or not\n",
    "purchase['QtySold'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### identify number of unique transactions per customer\n",
    "unique_purchases = purchase[['Customer_ID','UniquePurchases']]\n",
    "x = unique_purchases.groupby('Customer_ID',as_index=False).nunique()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sum quantity of items purchased per unique product\n",
    "item_purchases = purchase[['Customer_ID','UPCDescription','QtySold']]\n",
    "y = item_purchases.groupby(['Customer_ID','UPCDescription'],as_index=False).sum()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create full table\n",
    "full_table = pd.merge(x,y,on = \"Customer_ID\",how='inner')\n",
    "full_table['rating'] = full_table['QtySold']/full_table['UniquePurchases'] ### create implicit rating\n",
    "full_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get min and max ratings per customer\n",
    "rating_transform = full_table[['Customer_ID','rating']]\n",
    "rating_max = rating_transform.groupby('Customer_ID',as_index=False).max()\n",
    "rating_max['rating'] = rating_max['rating'] + 0.01\n",
    "rating_min = rating_transform.groupby('Customer_ID',as_index=False).min()\n",
    "rating_max.rename(columns = {'rating':'rating_max'},inplace=True)\n",
    "rating_min.rename(columns = {'rating':'rating_min'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###merge tables\n",
    "full_table2 = pd.merge(full_table,rating_max, on = 'Customer_ID',how='inner')\n",
    "full_table3 = pd.merge(full_table2,rating_min, on = 'Customer_ID',how='inner')\n",
    "full_table3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get scaled rating\n",
    "full_table3['scaled_rating'] = (10-1) * (full_table3['rating'] - full_table3['rating_min'])/(full_table3['rating_max'] - full_table3['rating_min']) + 1\n",
    "full_table3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#minimum number of times an item has been purchased\n",
    "min_item = 10\n",
    "#minimum number of times a customer has purchased\n",
    "min_purch = 10\n",
    "\n",
    "### identify items that have been purchased more than the min\n",
    "item_count = full_table3[[\"UPCDescription\",\"Customer_ID\"]].groupby(\"UPCDescription\").count()\n",
    "item_count = item_count[item_count[\"Customer_ID\"] >= min_item]\n",
    "\n",
    "### identify customers that have purchased more than the min\n",
    "customer_count = full_table3[[\"UPCDescription\",\"Customer_ID\"]].groupby(\"Customer_ID\").count()\n",
    "customer_count = customer_count[customer_count[\"UPCDescription\"] >= min_purch]\n",
    "\n",
    "### filter table on above criteria\n",
    "full_table3 = full_table3[full_table3[\"Customer_ID\"].isin(customer_count.index) & full_table3[\"UPCDescription\"].isin(item_count.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###preview table\n",
    "full_table3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create final ratings table and explore\n",
    "ratings = full_table3[['Customer_ID','UPCDescription','scaled_rating']]\n",
    "\n",
    "ratings.dtypes\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set up training data\n",
    "X = ratings.copy()\n",
    "y = ratings[\"Customer_ID\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### find median\n",
    "print(f\"The median of this rating range is {np.median(np.arange(np.min(ratings['scaled_rating']), (np.max(ratings['scaled_rating']) + 1)))}\")\n",
    "\n",
    "#define a baseline model to always return the median\n",
    "def baseline(Customer_ID, UPC, scale_median, *args):\n",
    "    return scale_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### defining score function\n",
    "def score(cf_model, X_test, *args):    \n",
    "    #Construct a list of item-customer tuples from the testing dataset\n",
    "    id_upc_pairs = zip(X_test[X_test.columns[0]], X_test[X_test.columns[1]])\n",
    "    \n",
    "    #Predict the rating for every customer-item tuple\n",
    "    y_pred = np.array([cf_model(customer, item, *args) for (customer, item) in id_upc_pairs])\n",
    "    \n",
    "    #Extract the actual ratings given by the users in the test data\n",
    "    y_true = np.array(X_test[X_test.columns[2]])\n",
    "\n",
    "    #Return the final RMSE score\n",
    "    return mean_squared_error(y_true, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define function for getting recommendations from base models\n",
    "def base_recommendations(Customer_id, N, cf_model, X_test, *args):   \n",
    "  #Construct a list of user-item tuples from the dataset\n",
    "    id_upc_pairs = zip(X_test[X_test.columns[0]], X_test[X_test.columns[1]])\n",
    "    \n",
    "    #Predict the rating for every customer-item tuple\n",
    "    y_pred = np.array([cf_model(customer, item, *args) for (customer, item) in id_upc_pairs])\n",
    "    \n",
    "    Customer_ID = np.array(X_test[X_test.columns[0]])\n",
    "    UPCDescription = np.array(X_test[X_test.columns[1]])\n",
    "    \n",
    "    ### join predictions with Customer_ID and UPC_Descriptionss\n",
    "    recommendations = pd.DataFrame({'Customer_ID':Customer_ID,'UPCDescription':list(UPCDescription),'Prediction': list(y_pred)})\n",
    "    #sort all predictions\n",
    "    recommendations = recommendations.sort_values('Prediction', ascending=False)\n",
    "    #remove all but brand name products\n",
    "    recommendations = recommendations.loc[(recommendations.UPCDescription.str.startswith('BN'))]\n",
    "    # filter on Customer_ID\n",
    "    recommendations = recommendations.loc[recommendations['Customer_ID'] == Customer_id]\n",
    "    #Return the final recommendations\n",
    "    return recommendations.head(N)\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### score basline model\n",
    "baseline_rmse = score(baseline,X_test,5.5)\n",
    "baseline_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get recommendations from baseline mode\n",
    "base_recommendations(2010, 10, baseline, X_test, 5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set up ratings pivot\n",
    "r_matrix = X_train.pivot_table(values='scaled_rating', index='Customer_ID', columns='UPCDescription')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_model(Customer_ID, UPCDescription, ratings_matrix, scale_median):\n",
    "    #Check if UPCDescription exists in ratings_matrix\n",
    "    if UPCDescription in ratings_matrix:\n",
    "        #Compute the mean of all the ratings given to the item\n",
    "        mean_rating = ratings_matrix[UPCDescription].mean()\n",
    "    \n",
    "    else:\n",
    "        #Default to scale median\n",
    "        mean_rating = scale_median\n",
    "    \n",
    "    return mean_rating\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### score mean model\n",
    "mean_rmse = score(mean_model, X_test, r_matrix, 5.5)\n",
    "mean_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_recommendations(2010, 10, mean_model, X_train, r_matrix, 5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creat item based based pivot\n",
    "r_matrix_item = X_train.pivot(values='scaled_rating', index='UPCDescription', columns='Customer_ID')\n",
    "\n",
    "#Create a dummy ratings matrix with all null values imputed to 0\n",
    "r_matrix_item_dummy = r_matrix_item.copy().fillna(0)\n",
    "\n",
    "#Compute the cosine similarity\n",
    "cosine_sim_item = cosine_similarity(r_matrix_item_dummy, r_matrix_item_dummy)\n",
    "                                    \n",
    "#Convert to pandas dataframe \n",
    "cosine_sim_item = pd.DataFrame(cosine_sim_item, index=r_matrix_item.index, columns=r_matrix_item.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### preview similarity matrix\n",
    "cosine_sim_item.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Item-Based Collaborative Filter using Weighted Mean Ratings\n",
    "def wmean(Customer_ID, UPCDescription, ratings_matrix, c_sim_matrix, median_rating):\n",
    "    \n",
    "    #Check if Customer_ID exists in r_matrix\n",
    "    if Customer_ID in ratings_matrix:\n",
    "        \n",
    "        #Get the similarity scores for the item in question with every other item\n",
    "        sim_scores = c_sim_matrix[UPCDescription]\n",
    "        \n",
    "        #Get the user ratings for the item in question\n",
    "        u_ratings = ratings_matrix[Customer_ID]\n",
    "        \n",
    "        #Extract the indices containing NaN in the m_ratings series\n",
    "        idx = u_ratings[u_ratings.isnull()].index\n",
    "        \n",
    "        #Drop the NaN values from the Series\n",
    "        u_ratings = u_ratings.dropna()\n",
    "        \n",
    "        #Drop the corresponding cosine scores from the sim_scores series\n",
    "        sim_scores = sim_scores.drop(idx)\n",
    "        \n",
    "        #Compute the final weighted mean\n",
    "        if sim_scores.sum() > 0:\n",
    "            wmean_rating = np.dot(sim_scores, u_ratings)/ sim_scores.sum()\n",
    "        else: # the book has zero cosine similarity with other items\n",
    "            wmean_rating = median_rating\n",
    "    \n",
    "    else:\n",
    "        #Default to a rating of 5.5 in the absence of any information\n",
    "        wmean_rating = median_rating\n",
    "    \n",
    "    return wmean_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### scored weighted mean model\n",
    "wmean_rmse = score(wmean, X_test, r_matrix_item, cosine_sim_item, 5.5)\n",
    "wmean_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get recommendations from weighted mean model\n",
    "base_recommendations(2010, 10, wmean, X_train, r_matrix_item, cosine_sim_item, 5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#examine distribution of ratings\n",
    "ratings.scaled_rating.plot(kind='hist', bins=4, title='Actual Ratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating Normal Predictor Model\n",
    "our_seed = 14\n",
    "\n",
    "#Define a Reader object\n",
    "reader = Reader(rating_scale=(1,11))\n",
    "\n",
    "#Create the dataset\n",
    "data = Dataset.load_from_df(ratings, reader)\n",
    "\n",
    "#Define the normal predictor\n",
    "normal_pred = NormalPredictor() \n",
    "\n",
    "## apply the seeds before cross validating\n",
    "random.seed(our_seed)\n",
    "np.random.seed(our_seed)\n",
    "\n",
    "#Evaluate RMSE\n",
    "algo_cv = cross_validate(normal_pred, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "print(algo_cv)\n",
    "\n",
    "#Extract average RMSE\n",
    "algo_rmse = np.mean(algo_cv['test_rmse'])\n",
    "print(f'\\nThe RMSE across five folds was {algo_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train on the whole dataset\n",
    "trainset = data.build_full_trainset()\n",
    "normal_pred.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply the seeds before predicting\n",
    "random.seed(our_seed)\n",
    "np.random.seed(our_seed)\n",
    "#run predictions\n",
    "pred_df = ratings.copy() #make a copy of the ratings that we can add columns to\n",
    "\n",
    "#get all the predictions\n",
    "pred_df['prediction'] = pred_df.apply(lambda x: normal_pred.predict(x['UPCDescription'], x['Customer_ID']).est, axis=1) \n",
    "\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Creating KNN Model\n",
    "our_seed = 14\n",
    "\n",
    "#Define a Reader object\n",
    "reader = Reader(rating_scale=(1,11)) # defaults to (0,5)\n",
    "\n",
    "#Create the dataset\n",
    "data = Dataset.load_from_df(ratings, reader)\n",
    "\n",
    "sim_options = {'user_based':False}\n",
    "\n",
    "#Define the algorithm object\n",
    "knn = KNNBasic(k=3, verbose=False,sim_options = sim_options)\n",
    "\n",
    "## apply the seeds before cross validating\n",
    "random.seed(our_seed)\n",
    "np.random.seed(our_seed)\n",
    "#Evaluate Model\n",
    "knn_cv = cross_validate(knn, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "print(knn_cv)\n",
    "\n",
    "#Extract average RMSE\n",
    "knn_rmse = np.mean(knn_cv['test_rmse'])\n",
    "print(f'\\nThe RMSE across five folds was {knn_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a Reader object\n",
    "reader = Reader(rating_scale=(1,11))\n",
    "\n",
    "#Create the dataset\n",
    "data = Dataset.load_from_df(ratings, reader)\n",
    "\n",
    "#get the raw ratings\n",
    "raw_ratings = data.raw_ratings\n",
    "\n",
    "# shuffle ratings\n",
    "random.seed(our_seed)\n",
    "np.random.seed(our_seed)\n",
    "random.shuffle(raw_ratings)\n",
    "\n",
    "#A = 90% of the data, B = 10% of the data\n",
    "threshold = int(.9 * len(raw_ratings))\n",
    "A_raw_ratings = raw_ratings[:threshold]\n",
    "B_raw_ratings = raw_ratings[threshold:]\n",
    "\n",
    "data.raw_ratings = A_raw_ratings  # data is now the set A\n",
    "\n",
    "# Select best algo with grid search.\n",
    "print('Grid Search...')\n",
    "param_grid = {'k': [3,5], 'min_k': [1,3]}\n",
    "grid_search = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], cv=3)\n",
    "grid_search.fit(data)\n",
    "\n",
    "knn_gs_algo = grid_search.best_estimator['rmse']\n",
    "\n",
    "# retrain on the whole set A\n",
    "trainset = data.build_full_trainset()\n",
    "knn_gs_algo.fit(trainset)\n",
    "\n",
    "# Compute biased accuracy on A \n",
    "predictions = knn_gs_algo.test(trainset.build_testset())\n",
    "print(f'Biased accuracy on A = {accuracy.rmse(predictions)}')\n",
    "\n",
    "# Compute unbiased accuracy on B\n",
    "testset = data.construct_testset(B_raw_ratings)  # testset is now the set B\n",
    "predictions = knn_gs_algo.test(testset)\n",
    "print(f'Unbiased accuracy on B = {accuracy.rmse(predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seeds\n",
    "random.seed(our_seed)\n",
    "np.random.seed(our_seed)\n",
    "\n",
    "#reset the data.raw_ratings to 100% of the data\n",
    "data.raw_ratings = raw_ratings\n",
    "\n",
    "#build a trainset\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "#build the algorithm with best parameters\n",
    "knn_gs_algo = grid_search.best_estimator['rmse']\n",
    "\n",
    "#fit to the data\n",
    "knn_gs_algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the SVD model\n",
    "svd = SVD()\n",
    "## apply the seeds before cross validating\n",
    "random.seed(our_seed)\n",
    "np.random.seed(our_seed)\n",
    "#Evaluate RMSE\n",
    "svd_cv = cross_validate(svd, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "#Extract average RMSE\n",
    "svd_rmse = np.mean(svd_cv['test_rmse'])\n",
    "print(f'\\nThe RMSE across five folds was {svd_rmse}')\n",
    "\n",
    "#train on the whole dataset\n",
    "trainset = data.build_full_trainset()\n",
    "svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the recommendations function\n",
    "def recommendations(ratings, Customer_ID, algo, N):\n",
    "    #create dataframe of unique items\n",
    "    sim_items = ratings.copy().drop(columns=['Customer_ID', 'scaled_rating']).drop_duplicates()\n",
    "    #generate the predicted this customer's predicted rating for each item based on filter selected\n",
    "    sim_items['Prediction'] = sim_items.apply(lambda x: algo.predict(Customer_ID, x['UPCDescription']).est, axis=1)\n",
    "    #add back Customer_ID\n",
    "    sim_items.insert(0, 'Customer_ID', Customer_ID)\n",
    "    #sort all predictions\n",
    "    sim_items = sim_items.sort_values('Prediction', ascending=False)\n",
    "    #remove all but brand name products\n",
    "    sim_items = sim_items.loc[(sim_items.UPCDescription.str.startswith('BN'))]\n",
    "    return sim_items.head(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get recommendations from KNN model\n",
    "recommendations(ratings, 2010, knn_gs_algo, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get recommendations from SVD Model\n",
    "recommendations(ratings, 2010, svd, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get recommendations from normal predictor\n",
    "recommendations(ratings, 2010, normal_pred, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### print all RMSE values\n",
    "print(\"Baseline RMSE:\",baseline_rmse)\n",
    "print(\"Mean RMSE:\",mean_rmse)\n",
    "print(\"Weighted Mean RMSE:\",wmean_rmse)\n",
    "print(\"Normal Predictor RMSE\",algo_rmse)\n",
    "print(\"KNN RMSE:\",knn_rmse)\n",
    "print(\"SVD RMSE:\",svd_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
